{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class Query:\n",
    "    \"\"\"\n",
    "    A Boolean algebra for queries\n",
    "\n",
    "        Q = (P(T*), and, or, not, {}, T*)\n",
    "\n",
    "    where T is the set of all ASCII characters, T* is the set of all strings of\n",
    "    ASCII characters, {} is the empty set, and P(T*) is the power set of T*.\n",
    "\n",
    "    This allows us to construct queries such as:\n",
    "\n",
    "        - \"(or (and cat dog) (not (or fish bird)))\"\n",
    "\n",
    "    which internally is represented as:\n",
    "\n",
    "        - ['or', ['and', 'cat', 'dog'], ['not', ['or', 'fish', 'bird']]]\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def from_query_string(cls, query: str):\n",
    "        query_obj = cls()\n",
    "        query_obj.tokens = query_obj.tokenize(query)\n",
    "        return query_obj\n",
    "\n",
    "    @classmethod\n",
    "    def from_tokens(cls, tokens):\n",
    "        query = cls()\n",
    "        query.tokens = tokens\n",
    "        return query\n",
    "\n",
    "    def tokenize(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Tokenize and stem the query.\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = re.findall(r'\\b\\w+\\b|\\(|\\)', query)\n",
    "\n",
    "        def _build(tokens):\n",
    "            \"\"\"Recursively process the tokens to compute the final set of matching documents.\"\"\"\n",
    "            # if not tokens:\n",
    "            #    raise ValueError(\"Unexpected end of query.\")\n",
    "\n",
    "            # if tokens[0] != '(':\n",
    "            #    raise ValueError(\"Expected '('\")\n",
    "\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "\n",
    "            result = []\n",
    "            if tokens[0].lower() not in {'and', 'or', 'not'}:\n",
    "                op = 'and'\n",
    "            else:\n",
    "                op = tokens.pop(0).lower()\n",
    "\n",
    "            result = [op]\n",
    "            while tokens and tokens[0] != ')':\n",
    "                if tokens[0] == '(':\n",
    "                    tokens.pop(0)  # Remove '('\n",
    "                    result.append(_build(tokens))  # New sub-list\n",
    "                else:\n",
    "                    term = tokens.pop(0)\n",
    "                    result.append(term)\n",
    "\n",
    "            # if not tokens:\n",
    "             #   raise ValueError(\"Mismatched parentheses in query.\")\n",
    "\n",
    "            # if tokens[0] != ')':\n",
    "            #    raise ValueError(\"Expected ')'\")\n",
    "            # tokens.pop(0)  # Remove ')'\n",
    "\n",
    "            if tokens and tokens[0] == ')':\n",
    "                tokens.pop(0)\n",
    "\n",
    "            return result\n",
    "\n",
    "        return _build(tokens)\n",
    "\n",
    "    def __and__(self, other: 'Query') -> 'Query':\n",
    "        return Query.from_tokens(['and', self.tokens, other.tokens])\n",
    "\n",
    "    def __or__(self, other: 'Query'):\n",
    "        return Query.from_tokens(['or', self.tokens, other.tokens])\n",
    "\n",
    "    def __invert__(self):\n",
    "        return Query.from_tokens(['not', self.tokens])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Query.from_tokens({self.tokens})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        def _build(tokens):\n",
    "            if isinstance(tokens, list):\n",
    "                return f\"({tokens[0]} {' '.join(_build(t) for t in tokens[1:])})\"\n",
    "            return tokens\n",
    "        return _build(self.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(and cat dog)\n",
      "Query.from_tokens(['and', 'cat', 'dog'])\n"
     ]
    }
   ],
   "source": [
    "q1 = Query.from_query_string(\"cat dog\")\n",
    "print(q1)\n",
    "print(repr(q1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['or', 'fish', 'bird']\n",
      "(not (or (not (and (and cat dog) (not (or fish bird)))) (or fish bird)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q2 = Query.from_query_string(\"or fish bird\")\n",
    "print(q2.tokens)\n",
    "\n",
    "\n",
    "q3 = ~(~(q1 & ~q2) | q2)\n",
    "print(q3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-cpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
