{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4254 | Document: Algebra is a branch of mathematics.\n",
      "Score: 0.0000 | Document: Search engines use algebraic methods.\n",
      "Score: 0.2980 | Document: Mathematics includes algebra, geometry, and calculus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/spinoza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class AlgebraicSearchEngine:\n",
    "    def __init__(self, docs, stemmer=None, vectorizer=None, stopwords_list=None):\n",
    "        # Initialize components with defaults if not provided\n",
    "        self.stemmer = stemmer or PorterStemmer()\n",
    "        self.vectorizer = vectorizer or TfidfVectorizer()\n",
    "        self.stopwords = set(stopwords_list or stopwords.words('english'))\n",
    "        \n",
    "        # Preprocess documents\n",
    "        processed_docs = [' '.join(self._preprocess(doc)) for doc in docs]\n",
    "        self.original_docs = docs\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(processed_docs).toarray().tolist()\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        \"\"\"Preprocess the text by removing punctuation, lowercasing, removing stopwords, and stemming.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "        words = text.split()\n",
    "        filtered_words = [self.stemmer.stem(word) for word in words if word not in self.stopwords]\n",
    "        return filtered_words\n",
    "    \n",
    "    def _tokenize_query(self, query):\n",
    "        \"\"\"Tokenize and stem the query.\"\"\"\n",
    "        tokens = re.findall(r'\\b\\w+\\b|\\(|\\)', query)\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def _compute_term_scores(self, term):\n",
    "        \"\"\"Compute the score for each document based on the term's vector.\"\"\"\n",
    "        term_vector = self.vectorizer.transform([term]).toarray()[0].tolist()\n",
    "        return [\n",
    "            sum(doc_val * term_val for doc_val, term_val in zip(doc_vec, term_vector))\n",
    "            for doc_vec in self.doc_vectors\n",
    "        ]\n",
    "    \n",
    "    def _recursive_search(self, tokens):\n",
    "        \"\"\"Recursively process the tokens to compute the final scores.\"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Unexpected end of query.\")\n",
    "        \n",
    "        operator = tokens.pop(0).upper()\n",
    "        if operator not in {'AND', 'OR', 'NOT'}:\n",
    "            raise ValueError(f\"Invalid operator: {operator}\")\n",
    "        \n",
    "        operands = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "                operands.append(self._recursive_search(tokens))\n",
    "            else:\n",
    "                term = tokens.pop(0)\n",
    "                operands.append(self._compute_term_scores(term))\n",
    "        \n",
    "        if not tokens:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        tokens.pop(0)  # Remove ')'\n",
    "        \n",
    "        if operator == 'AND':\n",
    "            # Element-wise minimum for AND operation\n",
    "            return [min(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'OR':\n",
    "            # Element-wise maximum for OR operation\n",
    "            return [max(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'NOT':\n",
    "            if len(operands) != 1:\n",
    "                raise ValueError(\"NOT operator requires exactly one operand.\")\n",
    "            # Simple NOT implementation: invert scores (assuming scores are between 0 and 1)\n",
    "            return [1 - score for score in operands[0]]\n",
    "    \n",
    "    def search(self, query):\n",
    "        \"\"\"Search the documents based on the algebraic query.\"\"\"\n",
    "        tokens = self._tokenize_query(query)\n",
    "        if not tokens or tokens.pop(0) != '(':\n",
    "            raise ValueError(\"Query must start with '('.\")\n",
    "        \n",
    "        scores = self._recursive_search(tokens)\n",
    "        return scores\n",
    "\n",
    "nltk.download('stopwords')\n",
    "documents = [\n",
    "    \"Algebra is a branch of mathematics.\",\n",
    "    \"Search engines use algebraic methods.\",\n",
    "    \"Mathematics includes algebra, geometry, and calculus.\"\n",
    "]\n",
    "\n",
    "engine = AlgebraicSearchEngine(documents)\n",
    "query = \"( AND algebra mathematics )\"\n",
    "results = engine.search(query)\n",
    "for doc, score in zip(engine.original_docs, results):\n",
    "    print(f\"Score: {score:.4f} | Document: {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class AlgebraicBooleanSearchEngine:\n",
    "    def __init__(self, docs, stemmer=None, vectorizer=None, stopwords_list=None):\n",
    "        # Initialize components with defaults if not provided\n",
    "        self.stemmer = stemmer or PorterStemmer()\n",
    "        self.vectorizer = vectorizer or TfidfVectorizer()\n",
    "        self.stopwords = set(stopwords_list or stopwords.words('english'))\n",
    "        \n",
    "        # Preprocess documents\n",
    "        self.processed_docs = [' '.join(self._preprocess(doc)) for doc in docs]\n",
    "        self.original_docs = docs\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(self.processed_docs).toarray().tolist()\n",
    "        \n",
    "        # Build Inverted Index for Boolean Search\n",
    "        self.inverted_index = self._build_inverted_index(self.processed_docs)\n",
    "        self.num_docs = len(docs)\n",
    "        self.all_docs_set = set(range(self.num_docs))\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        \"\"\"Preprocess the text by removing punctuation, lowercasing, removing stopwords, and stemming.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "        words = text.split()\n",
    "        filtered_words = [self.stemmer.stem(word) for word in words if word not in self.stopwords]\n",
    "        return filtered_words\n",
    "    \n",
    "    def _tokenize_query(self, query):\n",
    "        \"\"\"Tokenize and stem the query.\"\"\"\n",
    "        tokens = re.findall(r'\\b\\w+\\b|\\(|\\)', query)\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def _compute_term_scores(self, term):\n",
    "        \"\"\"Compute the score for each document based on the term's vector.\"\"\"\n",
    "        term_vector = self.vectorizer.transform([term]).toarray()[0].tolist()\n",
    "        return [\n",
    "            sum(doc_val * term_val for doc_val, term_val in zip(doc_vec, term_vector))\n",
    "            for doc_vec in self.doc_vectors\n",
    "        ]\n",
    "    \n",
    "    def _recursive_algebraic_search(self, tokens):\n",
    "        \"\"\"Recursively process the tokens to compute the final algebraic scores.\"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Unexpected end of query.\")\n",
    "        \n",
    "        operator = tokens.pop(0).upper()\n",
    "        if operator not in {'AND', 'OR', 'NOT'}:\n",
    "            raise ValueError(f\"Invalid operator: {operator}\")\n",
    "        \n",
    "        operands = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "                operands.append(self._recursive_algebraic_search(tokens))\n",
    "            else:\n",
    "                term = tokens.pop(0)\n",
    "                operands.append(self._compute_term_scores(term))\n",
    "        \n",
    "        if not tokens:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        tokens.pop(0)  # Remove ')'\n",
    "        \n",
    "        if operator == 'AND':\n",
    "            # Element-wise minimum for AND operation\n",
    "            return [min(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'OR':\n",
    "            # Element-wise maximum for OR operation\n",
    "            return [max(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'NOT':\n",
    "            if len(operands) != 1:\n",
    "                raise ValueError(\"NOT operator requires exactly one operand.\")\n",
    "            # Invert scores (assuming scores are between 0 and 1)\n",
    "            return [1 - score for score in operands[0]]\n",
    "    \n",
    "    def search_algebraic(self, query):\n",
    "        \"\"\"Perform an algebraic search based on TF-IDF vectors.\"\"\"\n",
    "        tokens = self._tokenize_query(query)\n",
    "        if not tokens or tokens.pop(0) != '(':\n",
    "            raise ValueError(\"Query must start with '('.\")\n",
    "        \n",
    "        scores = self._recursive_algebraic_search(tokens)\n",
    "        return scores\n",
    "    \n",
    "    def _build_inverted_index(self, processed_docs):\n",
    "        \"\"\"Build an inverted index mapping terms to the set of document indices containing them.\"\"\"\n",
    "        inverted = {}\n",
    "        for idx, doc in enumerate(processed_docs):\n",
    "            terms = set(doc.split())  # Split the doc into words\n",
    "            for term in terms:\n",
    "                if term in inverted:\n",
    "                    inverted[term].add(idx)\n",
    "                else:\n",
    "                    inverted[term] = {idx}\n",
    "        return inverted\n",
    "    \n",
    "    def _recursive_boolean_search(self, tokens):\n",
    "        \"\"\"Recursively process the tokens to compute the final set of matching documents.\"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Unexpected end of query.\")\n",
    "        \n",
    "        operator = tokens.pop(0).upper()\n",
    "        if operator not in {'AND', 'OR', 'NOT'}:\n",
    "            raise ValueError(f\"Invalid operator: {operator}\")\n",
    "        \n",
    "        operands = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "                operands.append(self._recursive_boolean_search(tokens))\n",
    "            else:\n",
    "                term = tokens.pop(0)\n",
    "                operands.append(self.inverted_index.get(term, set()))\n",
    "        \n",
    "        if not tokens:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        tokens.pop(0)  # Remove ')'\n",
    "        \n",
    "        if operator == 'AND':\n",
    "            return set.intersection(*operands) if operands else set()\n",
    "        elif operator == 'OR':\n",
    "            return set.union(*operands) if operands else set()\n",
    "        elif operator == 'NOT':\n",
    "            if len(operands) != 1:\n",
    "                raise ValueError(\"NOT operator requires exactly one operand.\")\n",
    "            return self.all_docs_set - operands[0]\n",
    "    \n",
    "    def search_boolean(self, query):\n",
    "        \"\"\"Perform a boolean search based on exact term matching.\"\"\"\n",
    "        tokens = self._tokenize_query(query)\n",
    "        if not tokens or tokens.pop(0) != '(':\n",
    "            raise ValueError(\"Query must start with '('.\")\n",
    "        \n",
    "        matching_docs = self._recursive_boolean_search(tokens)\n",
    "        # Generate scores: 1 for matching documents, 0 for others\n",
    "        scores = [1.0 if idx in matching_docs else 0.0 for idx in range(self.num_docs)]\n",
    "        return scores\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "documents = [\n",
    "    \"Algebra is a branch of mathematics.\",\n",
    "    \"Search engines use algebraic methods.\",\n",
    "    \"Mathematics includes algebra, geometry, and calculus.\",\n",
    "    \"Geometry is another branch of mathematics.\",\n",
    "    \"Calculus and algebra are fundamental to mathematics.\"\n",
    "]\n",
    "\n",
    "engine = AlgebraicBooleanSearchEngine(documents)\n",
    "\n",
    "# Algebraic Search Example\n",
    "algebraic_query = \"( AND algebra mathematics )\"\n",
    "algebraic_results = engine.search_algebraic(algebraic_query)\n",
    "print(\"Algebraic Search Results:\")\n",
    "for doc, score in zip(engine.original_docs, algebraic_results):\n",
    "    print(f\"Score: {score:.4f} | Document: {doc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Boolean Search Example\n",
    "boolean_query = \"( AND algebra ( OR geometry ( NOT calculus )) )\"\n",
    "boolean_results = engine.search_boolean(boolean_query)\n",
    "print(\"Boolean Search Results:\")\n",
    "for doc, score in zip(engine.original_docs, boolean_results):\n",
    "    match_status = \"MATCH\" if score == 1.0 else \"NO MATCH\"\n",
    "    print(f\"Score: {score:.1f} | Document: {doc} | {match_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming the AlgebraicBooleanSearchEngine class is defined in a module named search_engine.py\n",
    "# from search_engine import AlgebraicBooleanSearchEngine\n",
    "\n",
    "# For demonstration, I'll include the class definition here.\n",
    "class AlgebraicBooleanSearchEngine:\n",
    "    def __init__(self, docs, stemmer=None, vectorizer=None, stopwords_list=None):\n",
    "        # Initialize components with defaults if not provided\n",
    "        self.stemmer = stemmer or PorterStemmer()\n",
    "        self.vectorizer = vectorizer or TfidfVectorizer()\n",
    "        self.stopwords = set(stopwords_list or stopwords.words('english'))\n",
    "        \n",
    "        # Preprocess documents\n",
    "        self.processed_docs = [' '.join(self._preprocess(doc)) for doc in docs]\n",
    "        self.original_docs = docs\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(self.processed_docs).toarray().tolist()\n",
    "        \n",
    "        # Build Inverted Index for Boolean Search\n",
    "        self.inverted_index = self._build_inverted_index(self.processed_docs)\n",
    "        self.num_docs = len(docs)\n",
    "        self.all_docs_set = set(range(self.num_docs))\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        \"\"\"Preprocess the text by removing punctuation, lowercasing, removing stopwords, and stemming.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "        words = text.split()\n",
    "        filtered_words = [self.stemmer.stem(word) for word in words if word not in self.stopwords]\n",
    "        return filtered_words\n",
    "    \n",
    "    def _tokenize_query(self, query):\n",
    "        \"\"\"Tokenize and stem the query.\"\"\"\n",
    "        tokens = re.findall(r'\\b\\w+\\b|\\(|\\)', query)\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def _compute_term_scores(self, term):\n",
    "        \"\"\"Compute the score for each document based on the term's vector.\"\"\"\n",
    "        term_vector = self.vectorizer.transform([term]).toarray()[0].tolist()\n",
    "        return [\n",
    "            sum(doc_val * term_val for doc_val, term_val in zip(doc_vec, term_vector))\n",
    "            for doc_vec in self.doc_vectors\n",
    "        ]\n",
    "    \n",
    "    def _recursive_algebraic_search(self, tokens):\n",
    "        \"\"\"Recursively process the tokens to compute the final algebraic scores.\"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Unexpected end of query.\")\n",
    "        \n",
    "        operator = tokens.pop(0).upper()\n",
    "        if operator not in {'AND', 'OR', 'NOT'}:\n",
    "            raise ValueError(f\"Invalid operator: {operator}\")\n",
    "        \n",
    "        operands = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "                operands.append(self._recursive_algebraic_search(tokens))\n",
    "            else:\n",
    "                term = tokens.pop(0)\n",
    "                operands.append(self._compute_term_scores(term))\n",
    "        \n",
    "        if not tokens:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        tokens.pop(0)  # Remove ')'\n",
    "        \n",
    "        if operator == 'AND':\n",
    "            # Element-wise minimum for AND operation\n",
    "            return [min(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'OR':\n",
    "            # Element-wise maximum for OR operation\n",
    "            return [max(scores) for scores in zip(*operands)]\n",
    "        elif operator == 'NOT':\n",
    "            if len(operands) != 1:\n",
    "                raise ValueError(\"NOT operator requires exactly one operand.\")\n",
    "            # Invert scores (assuming scores are between 0 and 1)\n",
    "            return [1 - score for score in operands[0]]\n",
    "    \n",
    "    def search_algebraic(self, query):\n",
    "        \"\"\"Perform an algebraic search based on TF-IDF vectors.\"\"\"\n",
    "        tokens = self._tokenize_query(query)\n",
    "        if not tokens or tokens.pop(0) != '(':\n",
    "            raise ValueError(\"Query must start with '('.\")\n",
    "        \n",
    "        scores = self._recursive_algebraic_search(tokens)\n",
    "        return scores\n",
    "    \n",
    "    def _build_inverted_index(self, processed_docs):\n",
    "        \"\"\"Build an inverted index mapping terms to the set of document indices containing them.\"\"\"\n",
    "        inverted = {}\n",
    "        for idx, doc in enumerate(processed_docs):\n",
    "            terms = set(doc.split())  # Split the doc into words\n",
    "            for term in terms:\n",
    "                if term in inverted:\n",
    "                    inverted[term].add(idx)\n",
    "                else:\n",
    "                    inverted[term] = {idx}\n",
    "        return inverted\n",
    "    \n",
    "    def _recursive_boolean_search(self, tokens):\n",
    "        \"\"\"Recursively process the tokens to compute the final set of matching documents.\"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Unexpected end of query.\")\n",
    "        \n",
    "        operator = tokens.pop(0).upper()\n",
    "        if operator not in {'AND', 'OR', 'NOT'}:\n",
    "            raise ValueError(f\"Invalid operator: {operator}\")\n",
    "        \n",
    "        operands = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)  # Remove '('\n",
    "                operands.append(self._recursive_boolean_search(tokens))\n",
    "            else:\n",
    "                term = tokens.pop(0)\n",
    "                operands.append(self.inverted_index.get(term, set()))\n",
    "        \n",
    "        if not tokens:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        tokens.pop(0)  # Remove ')'\n",
    "        \n",
    "        if operator == 'AND':\n",
    "            return set.intersection(*operands) if operands else set()\n",
    "        elif operator == 'OR':\n",
    "            return set.union(*operands) if operands else set()\n",
    "        elif operator == 'NOT':\n",
    "            if len(operands) != 1:\n",
    "                raise ValueError(\"NOT operator requires exactly one operand.\")\n",
    "            return self.all_docs_set - operands[0]\n",
    "    \n",
    "    def search_boolean(self, query):\n",
    "        \"\"\"Perform a boolean search based on exact term matching.\"\"\"\n",
    "        tokens = self._tokenize_query(query)\n",
    "        if not tokens or tokens.pop(0) != '(':\n",
    "            raise ValueError(\"Query must start with '('.\")\n",
    "        \n",
    "        matching_docs = self._recursive_boolean_search(tokens)\n",
    "        # Generate scores: 1 for matching documents, 0 for others\n",
    "        scores = [1.0 if idx in matching_docs else 0.0 for idx in range(self.num_docs)]\n",
    "        return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......F\n",
      "======================================================================\n",
      "FAIL: test_algebraic_search_not (__main__.TestAlgebraicBooleanSearchEngine.test_algebraic_search_not)\n",
      "Test algebraic search with a NOT query.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_281050/424487080.py\", line 64, in test_algebraic_search_not\n",
      "    self.assertEqual(scores[idx], 0.0)\n",
      "AssertionError: 0.47080139270829086 != 0.0\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_preprocessing (__main__.TestAlgebraicBooleanSearchEngine.test_preprocessing)\n",
      "Test if preprocessing correctly processes documents.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_281050/424487080.py\", line 24, in test_preprocessing\n",
      "    self.assertEqual(self.engine.processed_docs, expected_processed_docs)\n",
      "AssertionError: Lists differ: ['alg[15 chars]hemat', 'search engin use algebra method', 'ma[107 chars]mat'] != ['alg[15 chars]hematic', 'search engine use algebra method', [112 chars]tic']\n",
      "\n",
      "First differing element 0:\n",
      "'algebra branch mathemat'\n",
      "'algebra branch mathematic'\n",
      "\n",
      "- ['algebra branch mathemat',\n",
      "+ ['algebra branch mathematic',\n",
      "?                          ++\n",
      "\n",
      "-  'search engin use algebra method',\n",
      "+  'search engine use algebra method',\n",
      "?               +\n",
      "\n",
      "-  'mathemat includ algebra geometri calculu',\n",
      "?         --\n",
      "\n",
      "+  'mathem includ algebra geometri calculu',\n",
      "-  'geometri anoth branch mathemat',\n",
      "+  'geometri anoth branch mathematic',\n",
      "?                                 ++\n",
      "\n",
      "-  'calculu algebra fundament mathemat']\n",
      "+  'calculu algebra fundament mathematic']\n",
      "?                                     ++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.029s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Algebra is a branch of mathematics. 0.0\n",
      "1 Search engines use algebraic methods. 0.0\n",
      "2 Mathematics includes algebra, geometry, and calculus. 0.47080139270829086\n",
      "3 Geometry is another branch of mathematics. 0.498511878090309\n",
      "4 Calculus and algebra are fundamental to mathematics. 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7aeb073e7790>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test Class\n",
    "class TestAlgebraicBooleanSearchEngine(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        \"\"\"Set up a common search engine instance for all tests.\"\"\"\n",
    "        cls.documents = [# => 3\n",
    "            \"Algebra is a branch of mathematics.\",      \n",
    "            \"Search engines use algebraic methods.\",\n",
    "            \"Mathematics includes algebra, geometry, and calculus.\",\n",
    "            \"Geometry is another branch of mathematics.\",\n",
    "            \"Calculus and algebra are fundamental to mathematics.\"\n",
    "        ]\n",
    "        cls.engine = AlgebraicBooleanSearchEngine(cls.documents)\n",
    "    \n",
    "    def test_preprocessing(self):\n",
    "        \"\"\"Test if preprocessing correctly processes documents.\"\"\"\n",
    "        expected_processed_docs = [\n",
    "            \"algebra branch mathematic\",#\n",
    "            \"search engine use algebra method\",\n",
    "            \"mathem includ algebra geometri calculu\",\n",
    "            \"geometri anoth branch mathematic\",\n",
    "            \"calculu algebra fundament mathematic\"#\n",
    "        ]\n",
    "        self.assertEqual(self.engine.processed_docs, expected_processed_docs)\n",
    "    \n",
    "    def test_algebraic_search_simple_and(self):\n",
    "        \"\"\"Test algebraic search with a simple AND query.\"\"\"\n",
    "        query = \"( AND algebra mathematics )\"\n",
    "        scores = self.engine.search_algebraic(query)\n",
    "        # Expected: Documents 0,2,4 have both 'algebra' and 'mathematics'\n",
    "        # Since algebra and mathematics are present in all except document 3\n",
    "        # The actual scores depend on TF-IDF; here, we'll check that document 3 has score 0\n",
    "        self.assertEqual(scores[1], 0.0)\n",
    "        self.assertEqual(scores[3], 0.0)\n",
    "        # Check that other documents have non-zero scores\n",
    "        for idx in [0,2,4]:\n",
    "            self.assertGreater(scores[idx], 0.0)\n",
    "    \n",
    "    def test_algebraic_search_or(self):\n",
    "        \"\"\"Test algebraic search with an OR query.\"\"\"\n",
    "        query = \"( OR algebra method )\"\n",
    "        scores = self.engine.search_algebraic(query)\n",
    "        # All documents except document 1 have either 'algebra' or 'geometry'\n",
    "        expected_non_matching = [3]\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "        # Check that other documents have non-zero scores\n",
    "        for idx in range(len(self.documents)):\n",
    "            if idx not in expected_non_matching:\n",
    "                self.assertGreater(scores[idx], 0.0)\n",
    "    \n",
    "    def test_algebraic_search_not(self):\n",
    "        \"\"\"Test algebraic search with a NOT query.\"\"\"\n",
    "        query = \"(AND geometry ( NOT calculus ))\"\n",
    "        scores = self.engine.search_algebraic(query)\n",
    "        # Documents not containing 'calculus' are 0,1,3\n",
    "        expected_matching = [3]\n",
    "        expected_non_matching = [0,1,2,4]\n",
    "        for idx in [0,1,2,3,4]:\n",
    "            print(idx, self.documents[idx], scores[idx])\n",
    "        for idx in expected_matching:\n",
    "            self.assertGreater(scores[idx], 0.0)\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "    \n",
    "    def test_boolean_search_and_or(self):\n",
    "        \"\"\"Test boolean search with AND and OR operators.\"\"\"\n",
    "        query = \"( AND algebra ( OR geometry calculus ) )\"\n",
    "        scores = self.engine.search_boolean(query)\n",
    "        # Documents that contain 'algebra' AND ('geometry' OR 'calculus')\n",
    "        # Expected matching documents: 0 (algebra), 2 (algebra & geometry & calculus), 4 (algebra & calculus)\n",
    "        expected_matching = [2, 4]\n",
    "        expected_non_matching = [0, 1, 3]\n",
    "        for idx in expected_matching:\n",
    "            self.assertEqual(scores[idx], 1.0)\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "    \n",
    "    def test_boolean_search_not(self):\n",
    "        \"\"\"Test boolean search with NOT operator.\"\"\"\n",
    "        query = \"( AND algebra ( NOT calculus ) )\"\n",
    "        scores = self.engine.search_boolean(query)\n",
    "        # Documents that contain 'algebra' AND NOT 'calculus'\n",
    "        # Expected matching documents: 0,1\n",
    "        expected_matching = [0, 1]\n",
    "        expected_non_matching = [2,3,4]\n",
    "        for idx in expected_matching:\n",
    "            self.assertEqual(scores[idx], 1.0)\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "    \n",
    "    def test_boolean_search_or_not(self):\n",
    "        \"\"\"Test boolean search with OR and NOT operators.\"\"\"\n",
    "        query = \"( OR ( NOT algebra ) calculus )\"\n",
    "        scores = self.engine.search_boolean(query)\n",
    "        # Documents that contain NOT 'algebra' OR 'calculus'\n",
    "        # 'calculus' is in documents 2,4\n",
    "        # NOT 'algebra' is documents that do not have 'algebra': possibly none in this dataset\n",
    "        # However, in our inverted index, 'algebra' is in docs 0,1,2,4, so NOT 'algebra' is doc 3\n",
    "        # So matching documents: doc3, doc2, doc4\n",
    "        expected_matching = [2,3,4]\n",
    "        expected_non_matching = [0,1]\n",
    "        for idx in expected_matching:\n",
    "            self.assertEqual(scores[idx], 1.0)\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "    \n",
    "    def test_boolean_search_invalid_query(self):\n",
    "        \"\"\"Test boolean search with an invalid query.\"\"\"\n",
    "        invalid_queries = [\n",
    "            \"AND algebra mathematics )\",         # Missing opening parenthesis\n",
    "            \"( AND algebra mathematics\",         # Missing closing parenthesis\n",
    "            \"( XOR algebra mathematics )\",       # Invalid operator\n",
    "            \"( AND algebra ( OR geometry )\",     # Missing closing parenthesis\n",
    "            \"( NOT algebra geometry )\"            # NOT with two operands\n",
    "        ]\n",
    "        for query in invalid_queries:\n",
    "            with self.assertRaises(ValueError):\n",
    "                self.engine.search_boolean(query)\n",
    "    \n",
    "    def test_algebraic_search_invalid_query(self):\n",
    "        \"\"\"Test algebraic search with an invalid query.\"\"\"\n",
    "        invalid_queries = [\n",
    "            \"AND algebra mathematics )\",         # Missing opening parenthesis\n",
    "            \"( AND algebra mathematics\",         # Missing closing parenthesis\n",
    "            \"( XOR algebra mathematics )\",       # Invalid operator\n",
    "            \"( AND algebra ( OR geometry )\",     # Missing closing parenthesis\n",
    "            \"( NOT algebra mathematics )\"         # NOT with two operands\n",
    "        ]\n",
    "        for query in invalid_queries:\n",
    "            with self.assertRaises(ValueError):\n",
    "                self.engine.search_algebraic(query)\n",
    "    \n",
    "    def test_boolean_search_case_insensitivity(self):\n",
    "        \"\"\"Test boolean search with mixed case terms.\"\"\"\n",
    "        query = \"( AND Algebra ( OR Geometry Calculus ) )\"\n",
    "        scores = self.engine.search_boolean(query)\n",
    "        # Should behave the same as lowercase query\n",
    "        expected_matching = [2, 4]\n",
    "        expected_non_matching = [0, 1, 3]\n",
    "        for idx in expected_matching:\n",
    "            self.assertEqual(scores[idx], 1.0)\n",
    "        for idx in expected_non_matching:\n",
    "            self.assertEqual(scores[idx], 0.0)\n",
    "    \n",
    "    def test_algebraic_search_case_insensitivity2(self):\n",
    "        \"\"\"Test algebraic search with mixed case terms.\"\"\"\n",
    "        query = \"( AND Algebra Mathematics )\"\n",
    "        scores = self.engine.search_algebraic(query)\n",
    "        # Should behave the same as lowercase query\n",
    "        self.assertEqual(scores[3], 0.0)\n",
    "        for idx in [0,2,4]:\n",
    "            self.assertGreater(scores[idx], 0.0)\n",
    "\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geometri'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PorterStemmer().stem('algebraic'))\n",
    "print(PorterStemmer().stem('algebra'))\n",
    "print(PorterStemmer().stem('geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(AND cat (NOT bite) dog)\"# (AND dog quick) (NOT (AND boy jump)))\"\n",
    "#query = \"(AND cat (NOT dog))\"\n",
    "print(f\"Query: {query}\")\n",
    "# Query: (AND cat (NOT (OR dog men))\n",
    "print(f'Processed Query: {boolean_search_engine.process_query(query)}')\n",
    "# Processed Query: ['(', 'and', 'cat', '(', 'not', '(', 'or', 'dog', 'men', ')', ')']\n",
    "results = boolean_search_engine.search(query)\n",
    "print(f\"{results=} {results.shape=}\")\n",
    "# sort results by score\n",
    "results = sorted(enumerate(results), key=lambda x: x[1], reverse=True)\n",
    "# pretty print the results\n",
    "for i, doc in enumerate(boolean_search_engine.docs):\n",
    "    print(f\"Document {i}: {doc} => {results[i]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-cpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
